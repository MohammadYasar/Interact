# Interact: A Large-scale multimodal dataset comprising  human-human and human-robot collaboration data 

[**Paper**](paper.pdf)
| [**Website**](https://mohammadyasar.github.io/Interact/)
| [**Code**](https://github.com/MohammadYasar/Interact/tree/code)

![Interact](Interact-banner.png)


It features
- Human-Human and Human-Robot Collaboration Tasks
- Vaariations to investigate the impact of obstacles on human motion
- 3-D Skeleton data, RGB+D data from two viewpoints, ego-view of two participants
- Large-scale dataset (250+ episodes)


## Interact-HHC
![Interact-HHC](./static/images/Interact-HHC.jpg)

Comprises Human-Human Collaboration (3 Humans) data on a simulated assembly task [link](https://drive.google.com/drive/folders/1r0RX4bHvGpspQf4RSKlcObuNipqp8wKq?usp=drive_link).


## Interact-HRC
![Interact-HRC](./static/images/Interact-HRC.jpg)

Comprises Human-Robot Collaboration (3 Humans + 1 Robot) data on a simulated assembly task [link](https://drive.google.com/drive/folders/1upfF5MGCyu3XdU-5yUxMJ5--GEHu6qvx?usp=sharing).

## Citation

If you find this dataset useful for your research, please cite this work:
```
@inproceedings{yasar2024posetron,
  author={Yasar, Mohammad Samin and Islam, Md. Mofijul and Iqbal, Tariq},
  title={PoseTron: Enabling Close-Proximity Human-Robot Collaboration Through Multi-human Motion Prediction},
  booktitle={ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  year={2024}
}
```

